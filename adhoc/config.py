# config.py
OLLAMA_API_ENDPOINT = 'http://localhost:11434/api/generate/'
MODEL_NAME = 'llama3.1'
OUTPUT_FORMAT = 'latex'  # 'latex', 'markdown', 'word'
AUTHOR_NAME = 'Default Author'
LLM_PROVIDER = 'ollama'  # 'ollama', 'openai'
OPENAI_API_ENDPOINT = 'https://api.openai.com/v1/chat/completions'
OPENAI_API_KEY = ''  # Set via config command

